\chapter{Technology Beyond Our Control}
Artificial intelligence is in itself a useful tool for helping automated systems reach
their maximum potential. By working intelligently, computers can do more work in less
time and even consume less power. But there may be limits to the safety of intelligent
systems. Some dystopian views of the future fear that intelligent machines will grow
beyond our control and eventually take over the world. On the surface, these fears appear
rooted in science fiction, but their basis may not be entirely unfounded. This chapter
explores some of the less savory forecasts for the future of intelligent machines from
science fiction to scientific prediction.
\section{The Matrix: Intelligent Machines Succeed Humanity}
The cinema blockbuster The Matrix is more than just a sequence of good special
effects. It is a story that in many ways parallels Mary Shelley’s classic Frankenstein.
Both The Matrix and Frankenstein focus on the consequences of allowing science to get
beyond our control. Similarly, both plots derive from the human desire to create life, and
in particular, the fantasy of creating life from inanimate parts. The more modern story of
The Matrix highlights the idea of strong AI, and makes it more real by painting everyone
into a computerized world. The movie demonstrates an undesirable scenario that could
occur from the creation of strong artificial intelligence. More generally, it supports a
theory that sufficiently intelligent machines could replace humanity.\\
As previously discussed, one major goal of artificial intelligence is the
development of more efficient computerized tools. It is only natural that, given a set of
tools, we would seek to use them in the most efficient manner possible. Moreover, we as human beings seem generally fascinated with life. The very idea of creating life-like
programs may be what drives many to that pursuit. But it is possible that the unintended
consequences of developing intelligent machines, particularly those that might be
tantamount to a life form, could be grave for humanity.\\


\subsection{The Threefold Danger}
Based on the increasing power of computers, a strong artificial intelligence at
some point in the future would likely be capable of thinking at least as well as a human
being, particularly if it were based on a human-emulating neural network. The program
could solve a variety of problems, communicate with others, learn, and even be creative.
Of course this program doesn’t currently exist, but it could do all these things if it did. A
logical step would be to embody the intelligence within a machine such as a robot, in
order that it may be mobile and sustain its own existence (since a strong AI seeks to be
life- like). If many of these machines were built, they could be called a race of robots, and
a race of human-like intelligences would likely be a competitor for natural resources.\\
It is in the nature of human beings to adapt the world to our liking. In general we
consider ourselves to be the most important species on the planet. A race of robots might
have different ideal living conditions, and, if they were programmed to think like people,
robots would probably view themselves as the most important race \cite{two}. This kind
of competition illustrates a clear conflict that could result from the development of a
strong artificial intelligence.\\
Bill Joy, chief engineer at Sun Microsystems and author of the manifesto “Why
the Future Doesn’t Need Us,” argues that this is a conflict we would surely lose. Initially
we may have the advantage in sheer numbers, but that would quickly deteriorate. Intelligent robots could easily rebuild themselves. They would have no gestation period.
A new robot would be “born” in the time that it takes to put the pieces together. In a
factory setting, this could be hundreds per day, per factory. Robots would also have no
adolescence. It may take sixteen years to raise a reasonably capable human being, and
sixteen seconds to replicate a robotic intelligence. This represents a new type of danger
emerging in artificial intelligence technology. A bomb, no matter how powerful, can
only explode one time, but a race of robots could replicate itself so long as resources
were available, resources for which the robots would surely fight .\\
Joy also considers a less violent scenario in which robots accidentally squeeze
humanity out of existence. If an artificial intelligence was only as clever as human
beings, or maybe even less, humanity might still lose out. Even if the robotic race didn’t
aggressively pursue the destruction of humanity, they might still seek to change the
environment in which they live. They might also still seek to replicate, just as people
desire to have children. The robots would continue to serve their own best interests, and
consume the resources that people rely on. This type of behavior is similar to the way
people harvest forests and squeeze out the species of plants and animals that live there.\\
A third and still less violent future view is one in which strong artificial
intelligence never comes to fruition. It was this prospect that drove the hopelessly
antisocial Unabomber to misanthropic insanity. It is based on the idea that weak AI
continues to make machines work more efficiently and independently. In many ways, we
as a society are already dependent on these intelligent machines. There is not, for
example, enough human resource available to sustain the credit card industry without the
intelligent programs that rate and track people’s credit records. Nor is there sufficient human resource to maintain power if the very complex software in our nuclear plants
were gone. Joy points out what he calls the “New Luddite Challenge,” namely that we
must temper our desire for technology with our capability to live without that technology.
Strong AI notwithstanding, dependence on intelligent systems could be our downfall.\\
Joy, however, fails to adequately address the sustainability issue with regard to
technological dependence. Sustainability refers not to stagnation, but to our ability as a
society to continue to develop without using up or destroying the resources that support
our existence. Dependence on technology may be good, especially if that technology
enables us to extend our banks of otherwise depleting resources. We need only be wary
of technological dependence when that dependence causes us to overuse a nonrenewable
natural resource.
\section{Almost There}

The scenarios above are just a few of the many that have been considered by
scientists and science- fiction writers alike. But their significance lies in their urgency.
Several leading technological minds believe that machines with this kind of intelligence
may exist within our lifetimes. Hans Moravec writes in his 1999 book Robot: Mere
Machine to Transcendent Mind that he predicts human- like intelligence in computers by
the year 2040. These intelligent machines will cost roughly the same as a home computer
does today. Moravec’s estimates are based on his own professional experience and the
current trends of computing technology. In the past, however, his predictions have fallen
short of technological advance, rather than surpassing it.\\
Ray Kurzweil, another pioneer in computing technology, concurs with Moravec
on all these predictions save one: Kurzweil believes that computers will surpass human
brain capacity in only twenty years. His estimate is based on a computer simulation of
human brain functions. Kurzweil used an abstraction of individual thoughts, called
chunks, to generate an electronic brain. Although his model was orders of magnitude less
complex than a real brain, Kurzweil argued that Moore’s Law predicts the forthcoming
availability of computing power capable of surpassing the capacity of the human brain
.\\
One final point from Joy raises concern that artificial intelligence may come to be
more than just a computer program. In his manifesto, Joy discusses his work with
nanotechnology, miniature machines. Showing similar progress to integrated circuits,
nanobots could some day be used in what is called a swarm network. Swarm technology
is based on tiny robotic devices that communicate via wireless network. They have very
little computing power individually, but are designed to work together in parallel
processing tasks. As this technology develops, swarm devices could be used in tandem
with neural networking technolo gy. By programming swarm devices to form a specific
neural structure, AI developers could create the danger that Joy fears most: a physical
embodiment of a strong artificial intelligence.\\
The development of artificial intelligence, while logical, could have far reaching
and unintended consequences. Several technology experts strongly support the idea that
truly intelligent machines will exist in the foreseeable future. Unlike other technologies,
however, AI systems could develop into a competitive race with which human beings
would have to deal in order to ensure our own survival. These observations underscore the need for ethical and pragmatic foresight in the development of new artificial
intelligence technologies. This is not to say, however, that the development of artificially
intelligent machines is an entirely fruitless endeavor.